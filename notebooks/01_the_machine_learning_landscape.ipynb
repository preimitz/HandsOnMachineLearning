{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b8f287",
   "metadata": {},
   "source": [
    "# Preface\n",
    "\n",
    "## Objective and Approach\n",
    "\n",
    "Goal: By the end of the book you should be able to implement programs capable of learning from data!\n",
    "\n",
    "Python Frameworks to Use:\n",
    "\n",
    "* Scikit-Learn: Easy to use, entry point to learning ML\n",
    "* TensorFlow: more complex library, great to train and run very large neural networks (NN)\n",
    "* Keras: high-level deep learning Application Programming Interface (API), makes it simple to train and run NN, comes with TensorFlow\n",
    "\n",
    "\n",
    "All code examples are already provided online at https://github.com/ageron/handson-ml3, as jupyter notebooks. This is just a personal repository to play with the code and summarize the book for myself.\n",
    "\n",
    "Prerequisites:\n",
    "\n",
    "* NumPy\n",
    "* Pandas\n",
    "* Matplotlib\n",
    "* Linear Algebra\n",
    "* Differential Calculus\n",
    "\n",
    "If not familiar, have a look at https://homl.info/tutorials. The book is divided into two parts: 1. The Fundamentals of Machine Learning (Scikit-Learn), and 2. Neural Networks and Deep Learning (TensorFlow+Keras). \n",
    "\n",
    "## Other Resources\n",
    "\n",
    "* Andrew Ng's ML course on Coursera: https://www.coursera.org/learn/machine-learning\n",
    "* Scikit-Learn's User Guide: https://scikit-learn.org/stable/user_guide.html\n",
    "* Interactive Tutorials: https://www.dataquest.io\n",
    "* ML blogs: https://www.quora.com/What-are-the-best-artificial-intelligence-blogs-newsletters\n",
    "* ML competitions: https://www.kaggle.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db49c3d8",
   "metadata": {},
   "source": [
    "# Chapter 1 - The Machine Learning Landscape\n",
    "\n",
    "This notebook follows the first chapter and plays with the examples given in the book. I will also try to answer the questions in the book that are asked to the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ad3409",
   "metadata": {},
   "source": [
    "## Prerequisites to run our code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897096f3",
   "metadata": {},
   "source": [
    "Make sure we use the required python version or above. Note to myself: I am using the system version of python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503ccc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91245e88",
   "metadata": {},
   "source": [
    "Import essential packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "152c1b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "import sklearn\n",
    "\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a55359",
   "metadata": {},
   "source": [
    "Use same plot settings as in the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cec2c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=12)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed832456",
   "metadata": {},
   "source": [
    "Make this notebook's output stable across runs, we choose a specific random seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45118fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ac40e",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "### Machine Learning in a Nutshell\n",
    "\n",
    "Machine Learning is the science (and art) of programming computers so they can learn from data. It is the \"field of study that gives computers the ability to learn without being explicitly programmed\" (Arthur Samuel, 1959).\n",
    "\n",
    "ML system:\n",
    "\n",
    "* Training set/data: Examples that the system uses to learn, each example is called a 'training instance/sample'\n",
    "* Model: ML system part that learns and makes predictions, e.g. NN, random forests\n",
    "\n",
    "Usual advantages of ML:\n",
    "* No fine-tuning or long list of rules: program can be shorter, be easier to maintain, be more accurate compared to classical computer programs\n",
    "* automatically adapts to changes (fluctuating environments) compared to classical computer programs\n",
    "* Complex problems that have no known algorithm, e.g. speech recognition\n",
    "* can help humans learn by identifying best predictors for tasks and reveal correlations $\\to$ Discover hidden patterns in big data (Data Mining)\n",
    "\n",
    "### Types of Machine Learning Systems\n",
    "\n",
    "Classify into categories dependend on:\n",
    "* How are they supervised? Examples: Supervised, unsupervised, semi-supervised, self-supervised, and others\n",
    "* Learning process: Online vs batch learning\n",
    "* Instance vs. model-based learning: compare new data points to known data points, or detecting patterns in training data and building predictive model\n",
    "\n",
    "#### Training Supervision\n",
    "\n",
    "We will discuss: Supervised learning, unsupervised learning, self-supervised learning, semi-supervised learning, and reinforcement learning\n",
    "\n",
    "##### Supervised Learning\n",
    "\n",
    "In supervised learning, the training set for the algorithm is *labeled* (right/wrong, cats/dogs, spam/ham, ...). As already can be guessed from the label examples, classification is a typical supervised learning task. Another example is to predict a *target* numeric value (e.g. price) given some features (age, brand, etc). This task is called regression.\n",
    "\n",
    "Typical tasks summarised:\n",
    "* Classification (commonly using labels)\n",
    "* Regression (commonly using targets)\n",
    "\n",
    "##### Unsupervised Learning\n",
    "\n",
    "In unsupervised learning, the training data is unlabeled. For examples, if you like to sort a lot of data into groups (clustering), or even further into sub-groups (hierarchical clustering). Another example are visualisation algorithms where you would like to find representations of complex data for plotting them easier. Closely related to that is dimensionality reduction where the data is simplified, for example by merging correlated features into one (feature extraction).\n",
    "\n",
    "Tip: It might be helpful to use a dimensionality reduction algorithm before feeding it to another ML algorithm, to save disk space, run faster, and maybe even perform better.\n",
    "\n",
    "Anomaly detection says if a new instance is \"normal\" (like the vast majority of training data) or is likely an anomaly/outlier (rare in data, or not in data). This can be used to remove outliers before using another ML algorithm. Similar is novelty detection. This requires very \"clean\" data and detects new instances that are different from all instances in the training data.\n",
    "\n",
    "Association rule learning discovers interesting relations between attributes in large data sets.\n",
    "\n",
    "Typical tasks summarised:\n",
    "* Clustering, hierarchical clustering\n",
    "* Visualisation\n",
    "* Dimensionality reduction\n",
    "* Anomaly detection\n",
    "* Novelty detection\n",
    "* Association rule learning\n",
    "\n",
    "##### Semi-supervised Learning\n",
    "\n",
    "Semi-supervised Learning algorithms are able to deal with data that is only partially labeled. This can be beneficial since labeling is time-consuming and costly. For example if you have a large photo collection, the unsupervised part of the algorithm might cluster pictures based on who is in there. Once you give a label (name) to all people, the algorithm can name everyone in every picture.\n",
    "So mostly it is a combinational of unsupervised+supervised algorithms. Once the data is all labeled, a supervised algorithm can take over.\n",
    "\n",
    "##### Self-supervised Learning\n",
    "\n",
    "The task is to generate a fully labeled dataset from a fully unlabeled one. For example, damaged or masked images (unlabeled) should recover the original image (labeled targets). This can be also used to categorize data since the algorithm should be able to learn which features to add for a certain category. This is called Transfer Learning.\n",
    "\n",
    "Question: Why is it called self-supervised learning when it is using labels in the training? Some might even consider it unsupervised learning since it deals with fully unlabeled datasets. But self-supervised learning uses (generated) labels during training, so is supervised in that regard. \n",
    "\n",
    "Summary: \n",
    "* unsupervised learning generally deals with clustering, dimensionality reduction, anomaly detection\n",
    "* self-supervised learning focuses on same tasks as supervised learning: classification, regression.\n",
    "\n",
    "##### Reinforcement Learning\n",
    "\n",
    "The learning system is called an agent which can observe the environment, select and perform actions, and get rewards or penalties in return. It is learning a strategy (policy) to only receive rewards. Examples are robots.\n",
    "\n",
    "#### Batch vs. Online Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36cd23e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
